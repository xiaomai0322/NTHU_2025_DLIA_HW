{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"C:/Users/micha/Desktop/113deep/HW4/nvda.us.txt\")\n",
    "\n",
    "df.columns\n",
    "df.info()\n",
    "df.isnull().sum()\n",
    "df = df.dropna()\n",
    "df.shape\n",
    "df.describe()\n",
    "# Áï´Âá∫È´òÂÉπËÆäÂåñË∂®Âã¢\n",
    "plot = df.plot('Date', 'High', figsize=(15, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(input_data, output_data, window_size, step):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(0, len(input_data) - window_size, step):\n",
    "        if not np.isnan(output_data[i + window_size]) and not np.isnan(input_data[i:(i + window_size)].sum()):\n",
    "            sequences.append(input_data[i:(i + window_size)])\n",
    "            labels.append(output_data[i + window_size])\n",
    "    return np.array(sequences), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== LSTM Ê®°Âûã ======\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "train_loss_records = {}\n",
    "# ========== ‰∏çÂêå window/stepÔºåÊ®ôÊ∫ñÂåñ vs Êú™Ê®ôÊ∫ñÂåñÊØîËºÉ ==========\n",
    "window_step_configs = [\n",
    "    (10, 15),\n",
    "    (8, 15),\n",
    "    (10, 10),\n",
    "    (3, 3)\n",
    "]\n",
    "\n",
    "window_step_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_size, step in window_step_configs:\n",
    "    for normalize_flag in [False, True]:\n",
    "        print(f\"\\n[Window/Step] Training window_size={window_size}, step={step}, normalize={normalize_flag}\")\n",
    "\n",
    "        features = df[['Open', 'High', 'Low', 'Close']]\n",
    "        labels = df['High'].shift(-1)\n",
    "\n",
    "        if normalize_flag:\n",
    "            features = (features - features.mean()) / features.std()\n",
    "\n",
    "        X, y = create_sequences(features.values, labels.values, window_size, step)\n",
    "\n",
    "        ind = np.linspace(0, len(X)-1, num=int(len(X)*0.1), dtype=int)\n",
    "        x_test = X[ind]\n",
    "        y_test = y[ind]\n",
    "        all_ind = np.arange(len(X))\n",
    "        remains_ind = np.delete(all_ind, ind)\n",
    "\n",
    "        X = X[remains_ind]\n",
    "        y = y[remains_ind]\n",
    "\n",
    "        ind = np.random.permutation(len(X))\n",
    "        X = X[ind]\n",
    "        y = y[ind]\n",
    "        split_point = int(X.shape[0]*0.8)\n",
    "\n",
    "        x_train = X[:split_point]\n",
    "        y_train = y[:split_point]\n",
    "        x_val = X[split_point:]\n",
    "        y_val = y[split_point:]\n",
    "\n",
    "        x_train = torch.from_numpy(x_train).float()\n",
    "        y_train = torch.from_numpy(y_train).float()\n",
    "        x_val = torch.from_numpy(x_val).float()\n",
    "        y_val = torch.from_numpy(y_val).float()\n",
    "        x_test = torch.from_numpy(x_test).float()\n",
    "        y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "        batch_size = 32\n",
    "\n",
    "        train_dataset = TensorDataset(x_train, y_train)\n",
    "        val_dataset = TensorDataset(x_val, y_val)\n",
    "        test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = LSTMModel(input_dim=4, hidden_dim=500, num_layers=2, output_dim=1).cuda()\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0)\n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        epochs = 100\n",
    "\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for features_batch, labels_batch in train_loader:\n",
    "                features_batch = features_batch.cuda()\n",
    "                labels_batch = labels_batch.cuda()\n",
    "                outputs = model(features_batch).squeeze(-1)\n",
    "                loss = criterion(outputs, labels_batch)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            avg_train_loss = total_loss / len(train_loader)\n",
    "            train_losses.append(avg_train_loss)\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for features_batch, labels_batch in val_loader:\n",
    "                    features_batch = features_batch.cuda()\n",
    "                    labels_batch = labels_batch.cuda()\n",
    "                    outputs = model(features_batch).squeeze(-1)\n",
    "                    loss = criterion(outputs, labels_batch)\n",
    "                    val_loss += loss.item()\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        pred_value = []\n",
    "        actual_value = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for features_batch, labels_batch in test_loader:\n",
    "                features_batch = features_batch.cuda()\n",
    "                outputs = model(features_batch).squeeze(-1)\n",
    "                pred_value.append(outputs.cpu())\n",
    "                actual_value.append(labels_batch)\n",
    "\n",
    "        pred_value = torch.cat(pred_value)\n",
    "        actual_value = torch.cat(actual_value)\n",
    "\n",
    "        mse = F.mse_loss(pred_value, actual_value)\n",
    "\n",
    "        window_step_results.append({\n",
    "            'Window Size': window_size,\n",
    "            'Step Size': step,\n",
    "            'Normalized': normalize_flag,\n",
    "            'Test MSE': mse.item()\n",
    "        })\n",
    "\n",
    "        train_loss_records[f'{window_size}-{step}-norm={normalize_flag}'] = (train_losses, val_losses)\n",
    "\n",
    "# È°ØÁ§∫ window/step ÁµêÊûú\n",
    "window_step_df = pd.DataFrame(window_step_results)\n",
    "print(\"\\n=== Window/Step Normalization Comparison ===\")\n",
    "print(tabulate(window_step_df, headers='keys', tablefmt='github', showindex=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== üü¢ Part 2Ôºö‰∏çÂêå Feature ÁµÑÂêàÔºåÊ®ôÊ∫ñÂåñ vs Êú™Ê®ôÊ∫ñÂåñÊØîËºÉ ==========\n",
    "feature_combinations = [\n",
    "    ['Open', 'High', 'Low', 'Close'],\n",
    "    ['Open', 'High', 'Low', 'Close', 'Volume'],\n",
    "    ['High', 'Low', 'Close'],\n",
    "    ['Open', 'Close', 'Volume'],\n",
    "    ['High', 'Volume']\n",
    "]\n",
    "\n",
    "feature_results = []\n",
    "\n",
    "fixed_window_size = 3\n",
    "fixed_step = 3\n",
    "\n",
    "for feature_set in feature_combinations:\n",
    "    for normalize_flag in [False, True]:\n",
    "        print(f\"\\n[Feature Set] Training features={feature_set}, normalize={normalize_flag}\")\n",
    "\n",
    "        features = df[feature_set]\n",
    "        labels = df['High'].shift(-1)\n",
    "\n",
    "        if normalize_flag:\n",
    "            features = (features - features.mean()) / features.std()\n",
    "\n",
    "        X, y = create_sequences(features.values, labels.values, window_size=fixed_window_size, step=fixed_step)\n",
    "\n",
    "        ind = np.linspace(0, len(X)-1, num=int(len(X)*0.1), dtype=int)\n",
    "        x_test = X[ind]\n",
    "        y_test = y[ind]\n",
    "        all_ind = np.arange(len(X))\n",
    "        remains_ind = np.delete(all_ind, ind)\n",
    "\n",
    "        X = X[remains_ind]\n",
    "        y = y[remains_ind]\n",
    "\n",
    "        ind = np.random.permutation(len(X))\n",
    "        X = X[ind]\n",
    "        y = y[ind]\n",
    "        split_point = int(X.shape[0]*0.8)\n",
    "\n",
    "        x_train = X[:split_point]\n",
    "        y_train = y[:split_point]\n",
    "        x_val = X[split_point:]\n",
    "        y_val = y[split_point:]\n",
    "\n",
    "        x_train = torch.from_numpy(x_train).float()\n",
    "        y_train = torch.from_numpy(y_train).float()\n",
    "        x_val = torch.from_numpy(x_val).float()\n",
    "        y_val = torch.from_numpy(y_val).float()\n",
    "        x_test = torch.from_numpy(x_test).float()\n",
    "        y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "        batch_size = 32\n",
    "\n",
    "        train_dataset = TensorDataset(x_train, y_train)\n",
    "        val_dataset = TensorDataset(x_val, y_val)\n",
    "        test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = LSTMModel(input_dim=len(feature_set), hidden_dim=500, num_layers=2, output_dim=1).cuda()\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0)\n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        epochs = 100\n",
    "\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            for features_batch, labels_batch in train_loader:\n",
    "                features_batch = features_batch.cuda()\n",
    "                labels_batch = labels_batch.cuda()\n",
    "                outputs = model(features_batch).squeeze(-1)\n",
    "                loss = criterion(outputs, labels_batch)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            avg_train_loss = total_loss / len(train_loader)\n",
    "            train_losses.append(avg_train_loss)\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for features_batch, labels_batch in val_loader:\n",
    "                    features_batch = features_batch.cuda()\n",
    "                    labels_batch = labels_batch.cuda()\n",
    "                    outputs = model(features_batch).squeeze(-1)\n",
    "                    loss = criterion(outputs, labels_batch)\n",
    "                    val_loss += loss.item()\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        pred_value = []\n",
    "        actual_value = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for features_batch, labels_batch in test_loader:\n",
    "                features_batch = features_batch.cuda()\n",
    "                outputs = model(features_batch).squeeze(-1)\n",
    "                pred_value.append(outputs.cpu())\n",
    "                actual_value.append(labels_batch)\n",
    "\n",
    "        pred_value = torch.cat(pred_value)\n",
    "        actual_value = torch.cat(actual_value)\n",
    "\n",
    "        mse = F.mse_loss(pred_value, actual_value)\n",
    "\n",
    "        feature_results.append({\n",
    "            'Features': str(feature_set),\n",
    "            'Normalized': normalize_flag,\n",
    "            'Test MSE': mse.item()\n",
    "        })\n",
    "\n",
    "        train_loss_records[f'{feature_set}-norm={normalize_flag}'] = (train_losses, val_losses)\n",
    "\n",
    "# È°ØÁ§∫ feature ÁµêÊûú\n",
    "feature_df = pd.DataFrame(feature_results)\n",
    "print(\"\\n=== Feature Combination Normalization Comparison ===\")\n",
    "print(tabulate(feature_df, headers='keys', tablefmt='github', showindex=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Áï´LossÊõ≤Á∑ö ======\n",
    "for key, (train_losses, val_losses) in train_loss_records.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=f'Train {key}')\n",
    "    plt.plot(val_losses, linestyle='--', label=f'Val {key}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training and Validation Loss Curves ({key})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kneeoa39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
