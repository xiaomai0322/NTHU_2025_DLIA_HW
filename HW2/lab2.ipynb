{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "609dcb62-c2f8-4c6d-9c89-63dc0148a87c"
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "###### Lab 2\n",
    "\n",
    "# National Tsing Hua University\n",
    "\n",
    "#### Spring 2025\n",
    "\n",
    "#### 11320IEEM 513600\n",
    "\n",
    "#### Deep Learning and Industrial Applications\n",
    "    \n",
    "## Lab 2: Predicting Heart Disease with Deep Learning\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "061c22d2-eec4-40f4-866b-ccaa2d9a2963",
    "tags": []
   },
   "source": [
    "### Introduction\n",
    "\n",
    "In the realm of healthcare, early detection and accurate prediction of diseases play a crucial role in patient care and management. Heart disease remains one of the leading causes of mortality worldwide, making the development of effective diagnostic tools essential. This lab leverages deep learning to predict the presence of heart disease in patients using a subset of 14 key attributes from the Cleveland Heart Disease Database. The objective is to explore and apply deep learning techniques to distinguish between the presence and absence of heart disease based on clinical parameters.\n",
    "\n",
    "Throughout this lab, you'll engage with the following key activities:\n",
    "- Use [Pandas](https://pandas.pydata.org) to process the CSV files.\n",
    "- Use [PyTorch](https://pytorch.org) to build an Artificial Neural Network (ANN) to fit the dataset.\n",
    "- Evaluate the performance of the trained model to understand its accuracy.\n",
    "\n",
    "### Attribute Information\n",
    "\n",
    "1. age: Age of the patient in years\n",
    "2. sex: (Male/Female)\n",
    "3. cp: Chest pain type (4 types: low, medium, high, and severe)\n",
    "4. trestbps: Resting blood pressure\n",
    "5. chol: Serum cholesterol in mg/dl\n",
    "6. fbs: Fasting blood sugar > 120 mg/dl\n",
    "7. restecg: Resting electrocardiographic results (values 0,1,2)\n",
    "8. thalach: Maximum heart rate achieved\n",
    "9. exang: Exercise induced angina\n",
    "10. oldpeak: Oldpeak = ST depression induced by exercise relative to rest\n",
    "11. slope: The slope of the peak exercise ST segment\n",
    "12. ca: Number of major vessels (0-3) colored by fluoroscopy\n",
    "13. thal: 3 = normal; 6 = fixed defect; 7 = reversible defect\n",
    "14. target: target have disease or not (1=yes, 0=no)\n",
    "\n",
    "### References\n",
    "- [UCI Heart Disease Data](https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data) for the dataset we use in this lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "ad594fc8-4989-40f3-b124-4550fe7df386"
   },
   "source": [
    "## A. Checking and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "42a3eafd-cbcd-4c56-82cb-83a0bfa2399e",
    "outputId": "ed5307f8-b55a-4d7f-e113-45f96b6d1591"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('heart_dataset_train_all.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34241797-60f0-4818-a44b-f5379948d621",
    "outputId": "a55c9a63-dc43-411b-ef46-2fb48db11690"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "026585db-a6d8-4062-85de-e3a7eaebed72",
    "outputId": "ed978caf-af66-4266-c951-17c64a0ed866"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69031e6d-0fb5-49d9-b723-a0d1fee08c3c",
    "outputId": "76dca713-ae8d-47bd-bbcb-491e8f249750"
   },
   "outputs": [],
   "source": [
    "# checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "cb3090f8-2cfa-4f56-8aa5-cf954bb19932"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38aadbee-d68f-4ae0-b842-b40800b0cac9",
    "outputId": "34aae2b5-7805-4cb1-81db-99a6a0cbd620"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "26a69fd5-3534-4d8e-b59a-6778bf47a479"
   },
   "outputs": [],
   "source": [
    "# Mapping 'sex' descriptions to numbers\n",
    "sex_description = {\n",
    "    'Male': 0,\n",
    "    'Female': 1,\n",
    "}\n",
    "df.loc[:, 'sex'] = df['sex'].map(sex_description)\n",
    "\n",
    "# Mapping 'cp' (chest pain) descriptions to numbers\n",
    "pain_description = {\n",
    "    'low': 0,\n",
    "    'medium': 1,\n",
    "    'high': 2,\n",
    "    'severe': 3\n",
    "}\n",
    "df.loc[:, 'cp'] = df['cp'].map(pain_description)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "051108c6-7011-4187-9e36-bd2944a019ca",
    "outputId": "ef50c90f-dc11-4bc8-d9e0-be42fd263593"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "8b999df5-09a1-4ce2-b068-f1afba448ff8",
    "outputId": "b687919c-7870-4c62-a58e-779e8db02f90"
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "8ce7a0c5-76d6-4863-ba61-0544a220962a"
   },
   "source": [
    "#### Converting the DataFrame to a NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# 資料預處理\n",
    "df = pd.read_csv('heart_dataset_train_all.csv').dropna()\n",
    "df['sex'] = df['sex'].map({'Male': 0, 'Female': 1})\n",
    "df['cp'] = df['cp'].map({'low': 0, 'medium': 1, 'high': 2, 'severe': 3})\n",
    "np_data = df.values\n",
    "np.random.shuffle(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分資料集\n",
    "split = int(0.7 * len(np_data))\n",
    "x_train, y_train = np_data[:split, :13], np_data[:split, 13]\n",
    "x_val, y_val = np_data[split:, :13], np_data[split:, 13]\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "x_val = torch.tensor(x_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(x_val, y_val), batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試資料\n",
    "test_data = pd.read_csv('heart_dataset_test.csv').values\n",
    "x_test = torch.tensor(test_data[:, :13], dtype=torch.float32)\n",
    "y_test = torch.tensor(test_data[:, 13], dtype=torch.long)\n",
    "test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 模型定義\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(13, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.BatchNorm1d(hidden_size // 2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
    "            nn.BatchNorm1d(hidden_size // 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(hidden_size // 4, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# ====== 可調整區 ======\n",
    "EPOCHS = 200\n",
    "PATIENCE = 100\n",
    "# ======================\n",
    "\n",
    "# 超參數組合\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "hidden_sizes = [128, 256, 512]\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for hidden_size in hidden_sizes:\n",
    "        print(f'Training with LR={lr}, Hidden={hidden_size}')\n",
    "        model = Model(hidden_size)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "        best_val_acc = -1\n",
    "        best_result = {}\n",
    "        wait = 0  # early stopping counter\n",
    "\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "            model.train()\n",
    "            total_loss, correct, total = 0.0, 0, 0\n",
    "            for x, y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                correct += (outputs.argmax(1) == y).sum().item()\n",
    "                total += y.size(0)\n",
    "            train_acc = 100. * correct / total\n",
    "            train_loss = total_loss / len(train_loader)\n",
    "\n",
    "            model.eval()\n",
    "            val_loss, val_correct, total = 0.0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for x, y in val_loader:\n",
    "                    outputs = model(x)\n",
    "                    loss = criterion(outputs, y)\n",
    "                    val_loss += loss.item()\n",
    "                    val_correct += (outputs.argmax(1) == y).sum().item()\n",
    "                    total += y.size(0)\n",
    "            val_acc = 100. * val_correct / total\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            train_accuracies.append(train_acc)\n",
    "            val_accuracies.append(val_acc)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            # Early stopping 檢查\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                wait = 0\n",
    "                best_result = {\n",
    "                    'train_loss': train_loss,\n",
    "                    'train_acc': train_acc,\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_acc': val_acc\n",
    "                }\n",
    "                torch.save(model.state_dict(), f'model_lr{lr}_h{hidden_size}.pth')\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= PATIENCE:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        # 測試\n",
    "        model.load_state_dict(torch.load(f'model_lr{lr}_h{hidden_size}.pth'))\n",
    "        model.eval()\n",
    "        test_loss, test_correct = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "                test_loss += loss.item()\n",
    "                test_correct += (outputs.argmax(1) == y).sum().item()\n",
    "        test_acc = 100. * test_correct / len(test_loader)\n",
    "        test_loss /= len(test_loader)\n",
    "\n",
    "        results.append([\n",
    "            lr, hidden_size,\n",
    "            best_result['train_loss'], best_result['train_acc'],\n",
    "            best_result['val_loss'], best_result['val_acc'],\n",
    "            test_loss, test_acc\n",
    "        ])\n",
    "\n",
    "        # 繪圖\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        ax[0].plot(train_accuracies, label='Train')\n",
    "        ax[0].plot(val_accuracies, label='Val')\n",
    "        ax[0].set_title('Model Accuracy')\n",
    "        ax[0].set_xlabel('Epochs')\n",
    "        ax[0].set_ylabel('Accuracy')\n",
    "        ax[0].legend()\n",
    "\n",
    "        ax[1].plot(train_losses, label='Train')\n",
    "        ax[1].plot(val_losses, label='Val')\n",
    "        ax[1].set_title('Model Loss')\n",
    "        ax[1].set_xlabel('Epochs')\n",
    "        ax[1].set_ylabel('Loss')\n",
    "        ax[1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'LR={lr}, Hidden={hidden_size}', fontsize=14, y=1.05)\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出為 CSV\n",
    "df_results = pd.DataFrame(results, columns=[\n",
    "    'Learning Rate', 'Hidden Size',\n",
    "    'Best Train Loss', 'Best Train Acc',\n",
    "    'Best Val Loss', 'Best Val Acc',\n",
    "    'Best Test Loss', 'Best Test Acc'\n",
    "])\n",
    "print(df_results)\n",
    "df_results.to_csv('hyperparameter_experiment_results.csv', index=False)\n",
    "print(\"✅ 結果已儲存至 hyperparameter_experiment_results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "kneeoa39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
